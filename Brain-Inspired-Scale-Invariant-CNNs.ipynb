{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"“7-scale-invariant-CNNs.ipynb”的副本","provenance":[{"file_id":"11lvHJslsBrn7lzABk1MqfcU6aRWLZYG-","timestamp":1593757661591}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DgJzF5aNOTdW","colab_type":"text"},"source":["## Code for implementing scale invariant CNNs.\n","\n","Here are the results of scale invariance CNNs applied on MNIST. The train images are taken from MNIST directly where as test images are scaled by a factor sampled uniformly from [0.5,2].\n","\n","```\n","RESULTS OF MULTISCALE CNN (bilinear)\n","Train accuracy of the model: 99.160 %\n","tensor(59497, device='cuda:0') 60000\n","Test accuracy of the model: 82.702 %\n","tensor(8271, device='cuda:0') 10000\n","```\n","\n","```\n","RESULTS OF MULTISCALE CNN (bicubic)\n","Train accuracy of the model: 99.160 %\n","tensor(59497, device='cuda:0') 60000\n","Test accuracy of the model: 82.702 %\n","tensor(8271, device='cuda:0') 10000\n","```\n","\n","```\n","RESULTS OF STANDARD CNN\n","Train accuracy of the model: 98.982 %\n","tensor(59390, device='cuda:0') 60000\n","Test accuracy of the model: 77.052 %\n","tensor(7706, device='cuda:0') 10000\n","```\n","\n","\n","Here are the results of scale invariance CNNs applied on MNIST. The train images are taken from MNIST directly where as test images are scaled by a factor sampled uniformly from [0.5,2.5].\n","\n","```\n","RESULTS OF MULTISCALE CNN (bilinear)\n","Train accuracy of the model: 99.210 %\n","tensor(59527, device='cuda:0') 60000\n","Test accuracy of the model: 72.533 %\n","tensor(7254, device='cuda:0') 10000\n","```\n","\n","```\n","RESULTS OF MULTISCALE CNN (bicubic)\n","Train accuracy of the model: 99.160 %\n","tensor(59497, device='cuda:0') 60000\n","Test accuracy of the model: 82.702 %\n","tensor(8271, device='cuda:0') 10000\n","```\n","\n","```\n","RESULTS OF STANDARD CNN\n","Train accuracy of the model: 99.090 %\n","tensor(59455, device='cuda:0') 60000\n","Test accuracy of the model: 66.873 %\n","tensor(6688, device='cuda:0') 10000\n","```\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"di4TD6kURjqA","colab_type":"text"},"source":["### Importing required libraries and setting things up"]},{"cell_type":"code","metadata":{"id":"21j-2kB6JyD8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1594302757936,"user_tz":-480,"elapsed":5896,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}},"outputId":"d989254b-7bec-4a7c-db3d-04ff05720f3d"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","!pip install torchviz"],"execution_count":188,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.5.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ndlXr-e4Rpjh","colab_type":"text"},"source":["### Rewriting Conv2d to implement the scale invariant convolutions\n"]},{"cell_type":"markdown","metadata":{"id":"Kw64jcc9SnNg","colab_type":"text"},"source":["#### Loading the base class"]},{"cell_type":"code","metadata":{"id":"ORbM5lGSOQOd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594302757937,"user_tz":-480,"elapsed":5873,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}}},"source":["from torch.nn.modules.utils import _single, _pair, _triple\n","from torch.nn.modules.conv import *\n","\n","def _reverse_repeat_tuple(t, n):\n","    \"\"\"Reverse the order of `t` and repeat each element for `n` times.\n","    This can be used to translate padding arg used by Conv and Pooling modules\n","    to the ones used by `F.pad`.\n","    \"\"\"\n","    return tuple(x for x in reversed(t) for _ in range(n))\n","\n","class _ConvNd(Module):\n","\n","    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n","                     'padding_mode', 'output_padding', 'in_channels',\n","                     'out_channels', 'kernel_size']\n","    __annotations__ = {'bias': Optional[torch.Tensor]}\n","\n","    def __init__(self, in_channels, out_channels, kernel_size, stride,\n","                 padding, dilation, transposed, output_padding,\n","                 groups, bias, padding_mode):\n","        super(_ConvNd, self).__init__()\n","        if in_channels % groups != 0:\n","            raise ValueError('in_channels must be divisible by groups')\n","        if out_channels % groups != 0:\n","            raise ValueError('out_channels must be divisible by groups')\n","        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n","        if padding_mode not in valid_padding_modes:\n","            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n","                valid_padding_modes, padding_mode))\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.transposed = transposed\n","        self.output_padding = output_padding\n","        self.groups = groups\n","        self.padding_mode = padding_mode\n","        # `_reversed_padding_repeated_twice` is the padding to be passed to\n","        # `F.pad` if needed (e.g., for non-zero padding types that are\n","        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n","        # reverse order than the dimension.\n","        self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n","        if transposed:\n","            self.weight = Parameter(torch.Tensor(\n","                in_channels, out_channels // groups, *kernel_size))\n","        else:\n","            self.weight = Parameter(torch.Tensor(\n","                out_channels, in_channels // groups, *kernel_size))\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            init.uniform_(self.bias, -bound, bound)\n","\n","    def extra_repr(self):\n","        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n","             ', stride={stride}')\n","        if self.padding != (0,) * len(self.padding):\n","            s += ', padding={padding}'\n","        if self.dilation != (1,) * len(self.dilation):\n","            s += ', dilation={dilation}'\n","        if self.output_padding != (0,) * len(self.output_padding):\n","            s += ', output_padding={output_padding}'\n","        if self.groups != 1:\n","            s += ', groups={groups}'\n","        if self.bias is None:\n","            s += ', bias=False'\n","        if self.padding_mode != 'zeros':\n","            s += ', padding_mode={padding_mode}'\n","        return s.format(**self.__dict__)\n","\n","    def __setstate__(self, state):\n","        super(_ConvNd, self).__setstate__(state)\n","        if not hasattr(self, 'padding_mode'):\n","            self.padding_mode = 'zeros'"],"execution_count":189,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0WYIq5PSpYY","colab_type":"text"},"source":["#### Writing out new convolutional filter. Same number of parameters but convolutions at multiple scales."]},{"cell_type":"code","metadata":{"id":"wNcy4bSNRm0Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594302757938,"user_tz":-480,"elapsed":5859,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}}},"source":["#\n","import random\n","\n","class Conv2dMultiScale(_ConvNd):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n","                 padding=0, dilation=1, groups=1,\n","                 bias=True, padding_mode='zeros', bicubic=False):\n","        kernel_size = _pair(kernel_size)\n","        stride = _pair(stride)\n","        padding = _pair(padding)\n","        dilation = _pair(dilation)\n","        super(Conv2dMultiScale, self).__init__(\n","            in_channels, out_channels, kernel_size, stride, padding, dilation,\n","            False, _pair(0), groups, bias, padding_mode)\n","        self.scale = nn.UpsamplingBilinear2d(size=(8,8))\n","\n","        self.bicubic = bicubic\n","        # self.scale = nn.functional.interpolate(size=(5,5), mode='bicubic')\n","\n","    def _conv_forward(self, input, weight):\n","\n","        # Typically this is the only thing that done\n","        out1 = F.conv2d(input, weight, self.bias, self.stride,\n","                        self.padding, self.dilation, self.groups)\n","        # print(out1.shape, \"out1\", weight.shape)\n","        \n","        # Upscaling the weights\n","        # We try bilinear and bicubic and test their performance\n","        \n","        if (self.bicubic):\n","          weight = F.interpolate(weight, size=(5,5), mode='bicubic')\n","        else:\n","          norm1 = torch.norm(weight)\n","          weight = self.scale(weight)\n","          norm2 = torch.norm(weight)\n","        # Adjusting padding to keep same output side\n","        padding = tuple(x+1 for x in self.padding)\n","        \n","        # Running convolution on the bigger scale\n","        out2 = F.conv2d(input, weight, self.bias, self.stride,\n","                        padding, self.dilation, self.groups)\n","        # print(out2.shape, \"out2\", weight.shape)\n","        \n","        \n","        # Returning the result\n","        out2 = F.interpolate(out2, size=out1.shape[2:], mode='bicubic')\n","        # print(out1.shape)\n","        # print(out2.shape)\n","        return out1 + out2\n","\n","    def forward(self, input):\n","        return self._conv_forward(input, self.weight)"],"execution_count":190,"outputs":[]},{"cell_type":"code","metadata":{"id":"nD7NbCG3hpTh","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UnpYqRAnM8Aq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1594302757939,"user_tz":-480,"elapsed":5854,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}},"outputId":"e6d26cd0-8497-4815-c43e-82f19a242c54"},"source":["# Understanding sizes of CNNs, ensuring it works\n","kernelSize = 3\n","m = Conv2dMultiScale(5, 3, kernelSize, stride=1, padding=(kernelSize - 1) // 2)\n","input = torch.randn(20, 5, 28, 28)\n","print(input.shape)\n","output = m(input)\n","output.shape"],"execution_count":191,"outputs":[{"output_type":"stream","text":["torch.Size([20, 5, 28, 28])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 3, 28, 28])"]},"metadata":{"tags":[]},"execution_count":191}]},{"cell_type":"markdown","metadata":{"id":"sO3Ks9GN1Tef","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"vNFpk9HcUCkf","colab_type":"text"},"source":["### Testing it on MNIST"]},{"cell_type":"code","metadata":{"id":"vU2W11EgUGCA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594302757939,"user_tz":-480,"elapsed":5839,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}}},"source":["import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import random\n","\n","num_classes = 10 # number of output classes discrete range [0,9]\n","num_epochs = 2 # number of times which the entire dataset is passed throughout the model\n","batch_size = 64  # the size of input data took for one iteration\n","lr = 1e-3 # size of step\n","\n","train_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.RandomAffine(degrees=0, scale=(0.5,2)),\n","    transforms.ToTensor(),\n","])\n","\n","train_data = dsets.MNIST(root = './data', train = True,\n","                        transform = train_transform, download = True)\n","\n","test_data = dsets.MNIST(root = './data', train = False,\n","                       transform = _test_transform())\n","\n","train_gen = torch.utils.data.DataLoader(dataset = train_data,\n","                                             batch_size = batch_size,\n","                                             shuffle = True)\n","\n","test_gen = torch.utils.data.DataLoader(dataset = test_data,\n","                                      batch_size = batch_size, \n","                                      shuffle = False)\n","\n"],"execution_count":192,"outputs":[]},{"cell_type":"code","metadata":{"id":"25WykbLSM74b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594302757940,"user_tz":-480,"elapsed":5828,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}}},"source":["class Net(nn.Module):\n","    def __init__(self, multiScale=True):\n","        super(Net, self).__init__()\n","        self.multiScale = multiScale\n","        if(multiScale):\n","          self.conv1 = Conv2dMultiScale(1, 32, 3, 1)\n","          self.conv2 = Conv2dMultiScale(32, 64, 3, 1)\n","        else:\n","          self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","          self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.fc = nn.Linear(9216, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        nn.Dropout()\n","        x = self.conv2(x)\n","        nn.Dropout()\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        nn.Dropout()\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","\n","net = Net(multiScale=True)"],"execution_count":193,"outputs":[]},{"cell_type":"code","metadata":{"id":"au_aM3ouNp8Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1594302851349,"user_tz":-480,"elapsed":99226,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}},"outputId":"6c354e5f-ae42-497d-a23a-177c76aa15f7"},"source":["if torch.cuda.is_available():\n","  net.cuda()\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam( net.parameters(), lr=lr)\n","\n","for epoch in range(num_epochs):\n","  for i ,(images,labels) in enumerate(train_gen):\n","    if torch.cuda.is_available():\n","      images = images.cuda()\n","      labels = labels.cuda()\n","    \n","    optimizer.zero_grad()\n","    outputs = net(images)\n","    loss = loss_function(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (i+1) % 100 == 0:\n","      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n","                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))"],"execution_count":194,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch [1/2], Step [100/937], Loss: 0.1299\n","Epoch [1/2], Step [200/937], Loss: 0.1726\n","Epoch [1/2], Step [300/937], Loss: 0.0964\n","Epoch [1/2], Step [400/937], Loss: 0.2244\n","Epoch [1/2], Step [500/937], Loss: 0.1703\n","Epoch [1/2], Step [600/937], Loss: 0.1206\n","Epoch [1/2], Step [700/937], Loss: 0.0563\n","Epoch [1/2], Step [800/937], Loss: 0.0726\n","Epoch [1/2], Step [900/937], Loss: 0.1046\n","Epoch [2/2], Step [100/937], Loss: 0.1755\n","Epoch [2/2], Step [200/937], Loss: 0.0946\n","Epoch [2/2], Step [300/937], Loss: 0.0389\n","Epoch [2/2], Step [400/937], Loss: 0.0427\n","Epoch [2/2], Step [500/937], Loss: 0.0435\n","Epoch [2/2], Step [600/937], Loss: 0.0792\n","Epoch [2/2], Step [700/937], Loss: 0.0173\n","Epoch [2/2], Step [800/937], Loss: 0.0894\n","Epoch [2/2], Step [900/937], Loss: 0.0208\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rM64k5QvTsPQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1594302863856,"user_tz":-480,"elapsed":111718,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}},"outputId":"148e03c1-1276-40c5-d0c7-5657997c9c78"},"source":["if(net.multiScale):\n","  print('RESULTS OF MULTISCALE CNN')\n","else:\n","  print('RESULTS OF STANDARD CNN')\n","\n","correct = 0\n","total = 0\n","\n","for images,labels in train_gen:\n","  if torch.cuda.is_available():\n","    images = images.cuda()\n","    labels = labels.cuda()\n","  \n","  output = net(images)\n","  _, predicted = torch.max(output,1)\n","  correct += (predicted == labels).sum()\n","  total += labels.size(0)\n","train_acc = (100*correct.cpu().numpy())/(total+1)\n","print('Train accuracy of the model: %.3f %%' %(train_acc))\n","print(correct, total)\n","\n","correct = 0\n","total = 0\n","for images,labels in test_gen:\n","  if torch.cuda.is_available():\n","    images = images.cuda()\n","    labels = labels.cuda()\n","  \n","  output = net(images)\n","  _, predicted = torch.max(output,1)\n","  correct += (predicted == labels).sum()\n","  total += labels.size(0)\n","test_acc = (100*correct.cpu().numpy())/(total+1)\n","print('Test accuracy of the model: %.3f %%' %(test_acc))\n","print(correct, total)"],"execution_count":195,"outputs":[{"output_type":"stream","text":["RESULTS OF MULTISCALE CNN\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"},{"output_type":"stream","text":["Train accuracy of the model: 98.562 %\n","tensor(59138, device='cuda:0') 60000\n","Test accuracy of the model: 80.402 %\n","tensor(8041, device='cuda:0') 10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lp690s02VZM9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594302863857,"user_tz":-480,"elapsed":111705,"user":{"displayName":"yiran wang","photoUrl":"","userId":"11675721244237465931"}}},"source":[""],"execution_count":195,"outputs":[]}]}