{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cone-and-rod.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGLV3rR0RvQHBAxiLqS4l4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanWangg/Brain-inspired-scale-invariant-CNN/blob/multi-column-network/Cone_and_rod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGh31IQ90Kqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0a450b66-afdb-4040-ae5f-d3adbf2aa3e5"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "!pip install torchviz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.5.1+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6kt0Yxm0hRR",
        "colab_type": "text"
      },
      "source": [
        "###Download the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqvss3qB0Z9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e438b8e4-7729-40b9-aa7d-497586082aa1"
      },
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data = dsets.CIFAR10(root = './data', train = True,\n",
        "                        transform = train_transform, download = True)\n",
        "\n",
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76tSevG73a29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e8c7d15-eaad-4c18-fdc3-3db67a9dac22"
      },
      "source": [
        "type(train_data[0][0])\n",
        "train_data[0][0].shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pybgjczw01YJ",
        "colab_type": "text"
      },
      "source": [
        "###Training and Testing Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuXQtiLU00eR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, lr=0.001, num_epochs=10, batch_size=64):  \n",
        "  if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam( net.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for i ,(images,labels) in enumerate(train_gen):\n",
        "      if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(images)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if (i+1) % 100 == 0:\n",
        "        print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                  %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))\n",
        "def test(net):  \n",
        "  if(net.multiScale):\n",
        "    print('RESULTS OF MULTISCALE CNN')\n",
        "  else:\n",
        "    print('RESULTS OF STANDARD CNN')\n",
        "  if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # loss_function = nn.CrossEntropyLoss()\n",
        "  for images,labels in train_gen:\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    output = net(images)\n",
        "    # loss = loss_function(outputs, labels)\n",
        "    _, predicted = torch.max(output,1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "  train_acc = (100*correct.cpu().numpy())/(total+1)\n",
        "  print('Train accuracy of the model: %.3f %%' %(train_acc))\n",
        "  print(correct, total)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images,labels in test_gen:\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    output = net(images)\n",
        "    # loss = loss_function(outputs, labels)\n",
        "    _, predicted = torch.max(output,1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "  test_acc = (100*correct.cpu().numpy())/(total+1)\n",
        "  print('Test accuracy of the model: %.3f %%' %(test_acc))\n",
        "  print(correct, total)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMzB8al4az2y",
        "colab_type": "text"
      },
      "source": [
        "###Create the Gaussian Kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRta9vXua5Pn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3501dc94-61e0-42b7-b2a4-32782ba7ce2a"
      },
      "source": [
        "import math\n",
        "import scipy\n",
        "\n",
        "def create_gau_filter(size, sigma):\n",
        "  x_mean = (size + 1) / 2\n",
        "  y_mean = (size + 1) / 2\n",
        "  pi = math.pi\n",
        "  sum = 0\n",
        "  matrix = [[0] * size for i in range(size)]\n",
        "  for i in range(size):\n",
        "    for j in range(size):\n",
        "      matrix[i][j] = (1 / sigma**2 / 2 / pi) * math.exp(-((i - x_mean)**2 + (j - y_mean)**2) / 2 / sigma**2) / sigma**2 / 2\n",
        "      sum += matrix[i][j]\n",
        "  matrix = torch.Tensor(matrix)\n",
        "  matrix = matrix / sum\n",
        "  # print(torch.sum(matrix))\n",
        "  return matrix\n",
        "\n",
        "def calculate(x, y, sigma):\n",
        "  return ((x**2 + y**2 - 2 * sigma**2) / sigma**4) * math.exp(-1 * (x**2 + y **2) / 2 * sigma**2)\n",
        "\n",
        "def create_log_filter(size, sigma):\n",
        "  matrix = [[0] * size for i in range(size)]\n",
        "  for i in range(size):\n",
        "    for j in range(size):\n",
        "      matrix[i][j] = calculate(i - size // 2, j - size // 2, sigma)\n",
        "  matrix = torch.Tensor(matrix)\n",
        "  # print(matrix)\n",
        "  # print(torch.sum(matrix))\n",
        "  return matrix\n",
        "\n",
        "create_log_filter(3, 1)\n",
        "\n",
        "create_gau_filter(5, 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.2167e-05, 2.7005e-04, 1.2103e-03, 1.9954e-03, 1.2103e-03],\n",
              "        [2.7005e-04, 3.2899e-03, 1.4744e-02, 2.4309e-02, 1.4744e-02],\n",
              "        [1.2103e-03, 1.4744e-02, 6.6079e-02, 1.0895e-01, 6.6079e-02],\n",
              "        [1.9954e-03, 2.4309e-02, 1.0895e-01, 1.7962e-01, 1.0895e-01],\n",
              "        [1.2103e-03, 1.4744e-02, 6.6079e-02, 1.0895e-01, 6.6079e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOODpnGJ0pRH",
        "colab_type": "text"
      },
      "source": [
        "###Define the Model Inspired By Cone and Rod Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubll2QXkeYrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "44f42c74-ffee-4ae6-ad8a-c4cc8257a6d8"
      },
      "source": [
        "conv = nn.Conv2d(3, 3, 5, 1, padding=1)\n",
        "conv.weight.shape\n",
        "x = torch.randn(3, 4, 5)\n",
        "print(x, 'x')\n",
        "x = torch.flatten(x, 1)\n",
        "print(x, 'x')\n",
        "\n",
        "y = torch.randn(3, 4, 5)\n",
        "print(y, 'y')\n",
        "y = torch.flatten(x, 1)\n",
        "print(y, 'y')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3483,  0.1918,  0.3405,  0.9588, -0.3387],\n",
            "         [-0.2818, -0.8398,  0.0582, -0.2635, -1.7742],\n",
            "         [ 0.1453,  0.9793, -1.4312, -0.3346,  1.2268],\n",
            "         [ 1.4233,  0.8699, -0.2412,  2.1485, -0.7564]],\n",
            "\n",
            "        [[-2.0579,  1.7260, -2.3870,  2.2155,  0.1215],\n",
            "         [-0.2720,  0.3469, -0.3147, -0.9637, -0.0929],\n",
            "         [-1.2641,  1.0472, -1.5853, -0.1638, -1.5156],\n",
            "         [-0.8209, -1.9388,  0.7356,  0.4327, -1.8492]],\n",
            "\n",
            "        [[ 1.0815,  0.2984, -0.3323,  0.5167, -0.0198],\n",
            "         [-1.4208,  1.1921, -1.0203,  1.4290, -0.2296],\n",
            "         [-0.5082,  2.2443,  0.9400, -0.4019,  0.0142],\n",
            "         [ 0.6599, -1.3512,  0.2596,  0.9150,  1.6426]]]) x\n",
            "tensor([[-0.3483,  0.1918,  0.3405,  0.9588, -0.3387, -0.2818, -0.8398,  0.0582,\n",
            "         -0.2635, -1.7742,  0.1453,  0.9793, -1.4312, -0.3346,  1.2268,  1.4233,\n",
            "          0.8699, -0.2412,  2.1485, -0.7564],\n",
            "        [-2.0579,  1.7260, -2.3870,  2.2155,  0.1215, -0.2720,  0.3469, -0.3147,\n",
            "         -0.9637, -0.0929, -1.2641,  1.0472, -1.5853, -0.1638, -1.5156, -0.8209,\n",
            "         -1.9388,  0.7356,  0.4327, -1.8492],\n",
            "        [ 1.0815,  0.2984, -0.3323,  0.5167, -0.0198, -1.4208,  1.1921, -1.0203,\n",
            "          1.4290, -0.2296, -0.5082,  2.2443,  0.9400, -0.4019,  0.0142,  0.6599,\n",
            "         -1.3512,  0.2596,  0.9150,  1.6426]]) x\n",
            "tensor([[[ 1.1222,  0.5325, -1.2792,  0.8271,  1.8845],\n",
            "         [-0.4749,  0.9564,  0.8709,  0.4923,  1.1050],\n",
            "         [ 0.6637, -2.0553,  0.2924, -0.1865, -1.8785],\n",
            "         [ 0.1433,  0.6734,  1.9215, -1.1033, -1.6473]],\n",
            "\n",
            "        [[ 0.9138, -1.1200,  0.9682, -0.9869,  0.5481],\n",
            "         [-1.4927, -1.6108,  0.4610,  0.4935, -0.3843],\n",
            "         [ 0.4763,  0.8086, -0.1167, -0.0364, -1.5932],\n",
            "         [-0.4148,  1.5063, -1.3356,  1.0990, -0.2225]],\n",
            "\n",
            "        [[-0.4906,  1.0975, -1.6587,  0.2803, -0.3603],\n",
            "         [ 0.4695, -0.9418,  1.6763,  0.3492,  2.3794],\n",
            "         [-1.1004, -0.2729,  1.2435,  0.6840,  0.1966],\n",
            "         [-0.6162,  0.2445,  0.2901, -1.2922,  0.8215]]]) y\n",
            "tensor([[-0.3483,  0.1918,  0.3405,  0.9588, -0.3387, -0.2818, -0.8398,  0.0582,\n",
            "         -0.2635, -1.7742,  0.1453,  0.9793, -1.4312, -0.3346,  1.2268,  1.4233,\n",
            "          0.8699, -0.2412,  2.1485, -0.7564],\n",
            "        [-2.0579,  1.7260, -2.3870,  2.2155,  0.1215, -0.2720,  0.3469, -0.3147,\n",
            "         -0.9637, -0.0929, -1.2641,  1.0472, -1.5853, -0.1638, -1.5156, -0.8209,\n",
            "         -1.9388,  0.7356,  0.4327, -1.8492],\n",
            "        [ 1.0815,  0.2984, -0.3323,  0.5167, -0.0198, -1.4208,  1.1921, -1.0203,\n",
            "          1.4290, -0.2296, -0.5082,  2.2443,  0.9400, -0.4019,  0.0142,  0.6599,\n",
            "         -1.3512,  0.2596,  0.9150,  1.6426]]) y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1iN4jRW0o0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "\n",
        "size = 3\n",
        "sigma = 2\n",
        "gau_kernel = create_gau_filter(size, sigma)\n",
        "log_kernel = create_log_filter(size, sigma)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, multiScale=True):\n",
        "        super(Net, self).__init__()\n",
        "        self.multiScale = multiScale\n",
        "        self.conv1_rod = nn.Conv2d(1, 64, 5, 1)\n",
        "        self.conv2_rod = nn.Conv2d(64, 64, 5, 1)\n",
        "        self.conv1_cone = nn.Conv2d(3, 64, 5, 1)\n",
        "        self.conv2_cone = nn.Conv2d(64, 64, 5, 1)\n",
        "        self.conv1_log = nn.Conv2d(1, 64, 5, 1)\n",
        "        self.conv2_log = nn.Conv2d(64, 64, 5, 1)\n",
        "        self.fc1_rod = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc1_cone = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc1_log = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc2_rod = nn.Linear(384, 192)\n",
        "        self.fc2_cone = nn.Linear(384, 192)\n",
        "        self.fc2_log = nn.Linear(384, 192)\n",
        "        self.gaussian = nn.Conv2d(3, 1, size, 1, padding=(size - 1) // 2)\n",
        "        self.log = nn.Conv2d(3, 1, size, 1, padding=(size - 1) // 2)\n",
        "        self.act = torch.nn.LeakyReLU()\n",
        "        if (self.multiScale):\n",
        "          self.fc = nn.Linear(192 * 3, 10)\n",
        "        else:\n",
        "          self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(self.fc.weight.shape)\n",
        "        with torch.no_grad():\n",
        "          self.gaussian.weight[:][:] = gau_kernel\n",
        "          self.log.weight[:][:] = log_kernel\n",
        "        rod = self.gaussian(x)\n",
        "        cone = torch.Tensor.clone(x)\n",
        "        log = self.log(x)\n",
        "        # cone part\n",
        "        # print(cone.shape, 'cone init')\n",
        "        cone = self.conv1_cone(cone)\n",
        "        cone = F.relu(cone)\n",
        "        cone = F.max_pool2d(cone, 2)\n",
        "        # print(cone.shape, 'cone conv1')\n",
        "        cone = self.conv2_cone(cone)\n",
        "        cone = F.relu(cone)\n",
        "        cone = F.max_pool2d(cone, 2)\n",
        "        # print(cone.shape, 'cone conv2')\n",
        "        cone = torch.flatten(cone, 1)\n",
        "        cone = self.fc1_cone(cone)\n",
        "        cone = F.relu(cone)\n",
        "        cone = self.fc2_cone(cone)\n",
        "        cone = F.relu(cone)\n",
        "        # print(cone.shape, 'cone')\n",
        "        if (self.multiScale):\n",
        "          # rod part\n",
        "          # print(rod.shape, 'rod init')\n",
        "          rod = self.conv1_rod(rod)\n",
        "          rod = F.relu(rod)\n",
        "          rod = F.max_pool2d(rod, 2)\n",
        "          # print(rod.shape, 'rod conv1')\n",
        "          rod = self.conv2_rod(rod)\n",
        "          rod = F.relu(rod)\n",
        "          rod = F.max_pool2d(rod, 2)\n",
        "          # print(rod.shape, 'rod conv2')\n",
        "          rod = torch.flatten(rod, 1)\n",
        "          rod = self.fc1_rod(rod)\n",
        "          rod = F.relu(rod)\n",
        "          rod = self.fc2_rod(rod)\n",
        "          rod = F.relu(rod)\n",
        "\n",
        "          log = self.conv1_log(log)\n",
        "          log = self.act(log)\n",
        "          log = F.max_pool2d(log, 2)\n",
        "          # print(rod.shape, 'rod conv1')\n",
        "          log = self.conv2_log(log)\n",
        "          log = self.act(log)\n",
        "          log = F.max_pool2d(log, 2)\n",
        "          # print(rod.shape, 'rod conv2')\n",
        "          log = torch.flatten(log, 1)\n",
        "          log = self.fc1_log(log)\n",
        "          log = self.act(log)\n",
        "          log = self.fc2_log(log)\n",
        "          log = self.act(log)\n",
        "          # print(rod.shape, 'rod')\n",
        "          # concatenate part\n",
        "          output = torch.cat([cone, rod, log], dim=1)\n",
        "          # output = torch.max(cone, rod)\n",
        "          # print(self.fc.weight.shape, output.shape)\n",
        "        output = self.fc(output)\n",
        "        # output = F.relu(output)\n",
        "        # output = self.fc1(output)\n",
        "        # output = F.relu(output)\n",
        "        # output = self.fc2(output)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "net = Net(multiScale=True)\n",
        "# train(net)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p7aP7HGnCei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "b9c51190-4dbd-414c-f547-d93f1db62fa5"
      },
      "source": [
        "for name, named_parameter in net.named_parameters():\n",
        "  if named_parameter.requires_grad:\n",
        "    print(name, named_parameter.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1_rod.weight torch.Size([64, 1, 5, 5])\n",
            "conv1_rod.bias torch.Size([64])\n",
            "conv2_rod.weight torch.Size([64, 64, 5, 5])\n",
            "conv2_rod.bias torch.Size([64])\n",
            "conv1_cone.weight torch.Size([64, 3, 5, 5])\n",
            "conv1_cone.bias torch.Size([64])\n",
            "conv2_cone.weight torch.Size([64, 64, 5, 5])\n",
            "conv2_cone.bias torch.Size([64])\n",
            "conv1_log.weight torch.Size([64, 1, 5, 5])\n",
            "conv1_log.bias torch.Size([64])\n",
            "conv2_log.weight torch.Size([64, 64, 5, 5])\n",
            "conv2_log.bias torch.Size([64])\n",
            "fc1_rod.weight torch.Size([384, 1600])\n",
            "fc1_rod.bias torch.Size([384])\n",
            "fc1_cone.weight torch.Size([384, 1600])\n",
            "fc1_cone.bias torch.Size([384])\n",
            "fc1_log.weight torch.Size([384, 1600])\n",
            "fc1_log.bias torch.Size([384])\n",
            "fc2_rod.weight torch.Size([192, 384])\n",
            "fc2_rod.bias torch.Size([192])\n",
            "fc2_cone.weight torch.Size([192, 384])\n",
            "fc2_cone.bias torch.Size([192])\n",
            "fc2_log.weight torch.Size([192, 384])\n",
            "fc2_log.bias torch.Size([192])\n",
            "gaussian.weight torch.Size([1, 3, 3, 3])\n",
            "gaussian.bias torch.Size([1])\n",
            "log.weight torch.Size([1, 3, 3, 3])\n",
            "log.bias torch.Size([1])\n",
            "fc.weight torch.Size([10, 576])\n",
            "fc.bias torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a72KK6RHiICc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd02bb5a-11c7-4dae-bd86-dcc56d26ea45"
      },
      "source": [
        "train(net, lr=0.0003, num_epochs=5)\n",
        "train(net, lr=0.001, num_epochs=10)\n",
        "train(net, lr=0.0003, num_epochs=5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/781], Loss: 1.8572\n",
            "Epoch [1/5], Step [200/781], Loss: 1.8065\n",
            "Epoch [1/5], Step [300/781], Loss: 1.6371\n",
            "Epoch [1/5], Step [400/781], Loss: 1.5467\n",
            "Epoch [1/5], Step [500/781], Loss: 1.5102\n",
            "Epoch [1/5], Step [600/781], Loss: 1.5464\n",
            "Epoch [1/5], Step [700/781], Loss: 1.5326\n",
            "Epoch [2/5], Step [100/781], Loss: 1.2468\n",
            "Epoch [2/5], Step [200/781], Loss: 1.0352\n",
            "Epoch [2/5], Step [300/781], Loss: 1.2656\n",
            "Epoch [2/5], Step [400/781], Loss: 1.1956\n",
            "Epoch [2/5], Step [500/781], Loss: 1.1424\n",
            "Epoch [2/5], Step [600/781], Loss: 1.3130\n",
            "Epoch [2/5], Step [700/781], Loss: 1.1043\n",
            "Epoch [3/5], Step [100/781], Loss: 1.0576\n",
            "Epoch [3/5], Step [200/781], Loss: 1.1049\n",
            "Epoch [3/5], Step [300/781], Loss: 1.2397\n",
            "Epoch [3/5], Step [400/781], Loss: 0.7911\n",
            "Epoch [3/5], Step [500/781], Loss: 1.2212\n",
            "Epoch [3/5], Step [600/781], Loss: 0.9235\n",
            "Epoch [3/5], Step [700/781], Loss: 0.7786\n",
            "Epoch [4/5], Step [100/781], Loss: 0.8869\n",
            "Epoch [4/5], Step [200/781], Loss: 0.9801\n",
            "Epoch [4/5], Step [300/781], Loss: 1.0665\n",
            "Epoch [4/5], Step [400/781], Loss: 0.8857\n",
            "Epoch [4/5], Step [500/781], Loss: 1.0501\n",
            "Epoch [4/5], Step [600/781], Loss: 0.9155\n",
            "Epoch [4/5], Step [700/781], Loss: 0.9078\n",
            "Epoch [5/5], Step [100/781], Loss: 0.8918\n",
            "Epoch [5/5], Step [200/781], Loss: 0.6774\n",
            "Epoch [5/5], Step [300/781], Loss: 0.7438\n",
            "Epoch [5/5], Step [400/781], Loss: 0.8864\n",
            "Epoch [5/5], Step [500/781], Loss: 0.6512\n",
            "Epoch [5/5], Step [600/781], Loss: 0.8043\n",
            "Epoch [5/5], Step [700/781], Loss: 0.8328\n",
            "Epoch [1/10], Step [100/781], Loss: 1.1113\n",
            "Epoch [1/10], Step [200/781], Loss: 0.7129\n",
            "Epoch [1/10], Step [300/781], Loss: 0.8651\n",
            "Epoch [1/10], Step [400/781], Loss: 1.1958\n",
            "Epoch [1/10], Step [500/781], Loss: 1.0489\n",
            "Epoch [1/10], Step [600/781], Loss: 0.8558\n",
            "Epoch [1/10], Step [700/781], Loss: 0.8600\n",
            "Epoch [2/10], Step [100/781], Loss: 0.7939\n",
            "Epoch [2/10], Step [200/781], Loss: 0.6800\n",
            "Epoch [2/10], Step [300/781], Loss: 0.4911\n",
            "Epoch [2/10], Step [400/781], Loss: 0.9597\n",
            "Epoch [2/10], Step [500/781], Loss: 0.9559\n",
            "Epoch [2/10], Step [600/781], Loss: 0.8438\n",
            "Epoch [2/10], Step [700/781], Loss: 0.5192\n",
            "Epoch [3/10], Step [100/781], Loss: 0.6231\n",
            "Epoch [3/10], Step [200/781], Loss: 0.6395\n",
            "Epoch [3/10], Step [300/781], Loss: 0.6746\n",
            "Epoch [3/10], Step [400/781], Loss: 0.5800\n",
            "Epoch [3/10], Step [500/781], Loss: 0.7338\n",
            "Epoch [3/10], Step [600/781], Loss: 0.2429\n",
            "Epoch [3/10], Step [700/781], Loss: 0.6016\n",
            "Epoch [4/10], Step [100/781], Loss: 0.3809\n",
            "Epoch [4/10], Step [200/781], Loss: 0.4442\n",
            "Epoch [4/10], Step [300/781], Loss: 0.4672\n",
            "Epoch [4/10], Step [400/781], Loss: 0.5155\n",
            "Epoch [4/10], Step [500/781], Loss: 0.3368\n",
            "Epoch [4/10], Step [600/781], Loss: 0.5272\n",
            "Epoch [4/10], Step [700/781], Loss: 0.3613\n",
            "Epoch [5/10], Step [100/781], Loss: 0.2883\n",
            "Epoch [5/10], Step [200/781], Loss: 0.1917\n",
            "Epoch [5/10], Step [300/781], Loss: 0.4130\n",
            "Epoch [5/10], Step [400/781], Loss: 0.2788\n",
            "Epoch [5/10], Step [500/781], Loss: 0.3965\n",
            "Epoch [5/10], Step [600/781], Loss: 0.4267\n",
            "Epoch [5/10], Step [700/781], Loss: 0.3909\n",
            "Epoch [6/10], Step [100/781], Loss: 0.1888\n",
            "Epoch [6/10], Step [200/781], Loss: 0.2909\n",
            "Epoch [6/10], Step [300/781], Loss: 0.1686\n",
            "Epoch [6/10], Step [400/781], Loss: 0.3278\n",
            "Epoch [6/10], Step [500/781], Loss: 0.3108\n",
            "Epoch [6/10], Step [600/781], Loss: 0.3158\n",
            "Epoch [6/10], Step [700/781], Loss: 0.2220\n",
            "Epoch [7/10], Step [100/781], Loss: 0.1494\n",
            "Epoch [7/10], Step [200/781], Loss: 0.3733\n",
            "Epoch [7/10], Step [300/781], Loss: 0.0682\n",
            "Epoch [7/10], Step [400/781], Loss: 0.1561\n",
            "Epoch [7/10], Step [500/781], Loss: 0.2514\n",
            "Epoch [7/10], Step [600/781], Loss: 0.1238\n",
            "Epoch [7/10], Step [700/781], Loss: 0.1910\n",
            "Epoch [8/10], Step [100/781], Loss: 0.2262\n",
            "Epoch [8/10], Step [200/781], Loss: 0.0189\n",
            "Epoch [8/10], Step [300/781], Loss: 0.3439\n",
            "Epoch [8/10], Step [400/781], Loss: 0.1399\n",
            "Epoch [8/10], Step [500/781], Loss: 0.0744\n",
            "Epoch [8/10], Step [600/781], Loss: 0.2159\n",
            "Epoch [8/10], Step [700/781], Loss: 0.1761\n",
            "Epoch [9/10], Step [100/781], Loss: 0.1116\n",
            "Epoch [9/10], Step [200/781], Loss: 0.0753\n",
            "Epoch [9/10], Step [300/781], Loss: 0.0557\n",
            "Epoch [9/10], Step [400/781], Loss: 0.1232\n",
            "Epoch [9/10], Step [500/781], Loss: 0.0863\n",
            "Epoch [9/10], Step [600/781], Loss: 0.0987\n",
            "Epoch [9/10], Step [700/781], Loss: 0.2733\n",
            "Epoch [10/10], Step [100/781], Loss: 0.2162\n",
            "Epoch [10/10], Step [200/781], Loss: 0.0675\n",
            "Epoch [10/10], Step [300/781], Loss: 0.1927\n",
            "Epoch [10/10], Step [400/781], Loss: 0.1173\n",
            "Epoch [10/10], Step [500/781], Loss: 0.0626\n",
            "Epoch [10/10], Step [600/781], Loss: 0.0396\n",
            "Epoch [10/10], Step [700/781], Loss: 0.1528\n",
            "Epoch [1/5], Step [100/781], Loss: 0.0149\n",
            "Epoch [1/5], Step [200/781], Loss: 0.0090\n",
            "Epoch [1/5], Step [300/781], Loss: 0.0471\n",
            "Epoch [1/5], Step [400/781], Loss: 0.0548\n",
            "Epoch [1/5], Step [500/781], Loss: 0.0142\n",
            "Epoch [1/5], Step [600/781], Loss: 0.0150\n",
            "Epoch [1/5], Step [700/781], Loss: 0.0032\n",
            "Epoch [2/5], Step [100/781], Loss: 0.0009\n",
            "Epoch [2/5], Step [200/781], Loss: 0.0030\n",
            "Epoch [2/5], Step [300/781], Loss: 0.0015\n",
            "Epoch [2/5], Step [400/781], Loss: 0.0111\n",
            "Epoch [2/5], Step [500/781], Loss: 0.0051\n",
            "Epoch [2/5], Step [600/781], Loss: 0.0026\n",
            "Epoch [2/5], Step [700/781], Loss: 0.0006\n",
            "Epoch [3/5], Step [100/781], Loss: 0.0004\n",
            "Epoch [3/5], Step [200/781], Loss: 0.0008\n",
            "Epoch [3/5], Step [300/781], Loss: 0.0004\n",
            "Epoch [3/5], Step [400/781], Loss: 0.0013\n",
            "Epoch [3/5], Step [500/781], Loss: 0.0029\n",
            "Epoch [3/5], Step [600/781], Loss: 0.0015\n",
            "Epoch [3/5], Step [700/781], Loss: 0.0004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7b997f359968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-970a74fa436c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, lr, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E65kcIAbj5M2",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzwzHOvcj06a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bdf727b3-3981-4d1a-9edb-3d1f73e33974"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\", \"\\nnet.Multiscale=\",net.multiScale)\n",
        "test(net)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Architecture:\n",
            " \n",
            "net.Multiscale= True\n",
            "RESULTS OF MULTISCALE CNN\n",
            "Train accuracy of the model: 99.998 %\n",
            "tensor(50000, device='cuda:0') 50000\n",
            "Test accuracy of the model: 72.703 %\n",
            "tensor(7271, device='cuda:0') 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHD_CAqHj6zP",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJF42N9gj25a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9fbc5dbf-863d-457e-a1ee-13b8dc5cc0e1"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(28),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\", \"\\nnet.Multiscale=\",net.multiScale)\n",
        "test(net)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Architecture:\n",
            " \n",
            "net.Multiscale= True\n",
            "RESULTS OF MULTISCALE CNN\n",
            "Train accuracy of the model: 99.998 %\n",
            "tensor(50000, device='cuda:0') 50000\n",
            "Test accuracy of the model: 66.853 %\n",
            "tensor(6686, device='cuda:0') 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZikaLQSLj8tM",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJWyHmLej4Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(24),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\", \"\\nnet.Multiscale=\",net.multiScale)\n",
        "test(net)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}