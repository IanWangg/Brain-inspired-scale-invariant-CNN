{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brain-Inspired-Scale-Invariant-CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanWangg/Brain-inspired-scale-invariant-CNN/blob/weightsharing-Inception-convlayer/Brain_Inspired_Scale_Invariant_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgJzF5aNOTdW",
        "colab_type": "text"
      },
      "source": [
        "## Code for implementing scale invariant CNNs.\n",
        "\n",
        "Here are the results of scale invariance CNNs applied on MNIST. The train images are taken from MNIST directly where as test images are scaled by a factor sampled uniformly from [0.5,2].\n",
        "\n",
        "```\n",
        "RESULTS OF MULTISCALE CNN (bilinear)\n",
        "Train accuracy of the model: 99.160 %\n",
        "tensor(59497, device='cuda:0') 60000\n",
        "Test accuracy of the model: 82.702 %\n",
        "tensor(8271, device='cuda:0') 10000\n",
        "```\n",
        "\n",
        "Here are the results of scale invariance CNNs applied on MNIST. The train images are taken from MNIST directly where as test images are scaled by a factor sampled uniformly from [0.5,2.5].\n",
        "\n",
        "```\n",
        "RESULTS OF MULTISCALE CNN (bilinear)\n",
        "Train accuracy of the model: 99.210 %\n",
        "tensor(59527, device='cuda:0') 60000\n",
        "Test accuracy of the model: 72.533 %\n",
        "tensor(7254, device='cuda:0') 10000\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di4TD6kURjqA",
        "colab_type": "text"
      },
      "source": [
        "### Importing required libraries and setting things up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21j-2kB6JyD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "87a320af-44ca-4da3-e564-f05c9692a297"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndlXr-e4Rpjh",
        "colab_type": "text"
      },
      "source": [
        "### Rewriting Conv2d to implement the scale invariant convolutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw64jcc9SnNg",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the base class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbM5lGSOQOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.modules.utils import _single, _pair, _triple\n",
        "from torch.nn.modules.conv import *\n",
        "\n",
        "def _reverse_repeat_tuple(t, n):\n",
        "    \"\"\"Reverse the order of `t` and repeat each element for `n` times.\n",
        "    This can be used to translate padding arg used by Conv and Pooling modules\n",
        "    to the ones used by `F.pad`.\n",
        "    \"\"\"\n",
        "    return tuple(x for x in reversed(t) for _ in range(n))\n",
        "\n",
        "class _ConvNd(Module):\n",
        "\n",
        "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
        "                     'padding_mode', 'output_padding', 'in_channels',\n",
        "                     'out_channels', 'kernel_size']\n",
        "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 padding, dilation, transposed, output_padding,\n",
        "                 groups, bias, padding_mode):\n",
        "        super(_ConvNd, self).__init__()\n",
        "        if in_channels % groups != 0:\n",
        "            raise ValueError('in_channels must be divisible by groups')\n",
        "        if out_channels % groups != 0:\n",
        "            raise ValueError('out_channels must be divisible by groups')\n",
        "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
        "        if padding_mode not in valid_padding_modes:\n",
        "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
        "                valid_padding_modes, padding_mode))\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.transposed = transposed\n",
        "        self.output_padding = output_padding\n",
        "        self.groups = groups\n",
        "        self.padding_mode = padding_mode\n",
        "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
        "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
        "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
        "        # reverse order than the dimension.\n",
        "        self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
        "        if transposed:\n",
        "            self.weight = Parameter(torch.Tensor(\n",
        "                in_channels, out_channels // groups, *kernel_size))\n",
        "        else:\n",
        "            self.weight = Parameter(torch.Tensor(\n",
        "                out_channels, in_channels // groups, *kernel_size))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
        "             ', stride={stride}')\n",
        "        if self.padding != (0,) * len(self.padding):\n",
        "            s += ', padding={padding}'\n",
        "        if self.dilation != (1,) * len(self.dilation):\n",
        "            s += ', dilation={dilation}'\n",
        "        if self.output_padding != (0,) * len(self.output_padding):\n",
        "            s += ', output_padding={output_padding}'\n",
        "        if self.groups != 1:\n",
        "            s += ', groups={groups}'\n",
        "        if self.bias is None:\n",
        "            s += ', bias=False'\n",
        "        if self.padding_mode != 'zeros':\n",
        "            s += ', padding_mode={padding_mode}'\n",
        "        return s.format(**self.__dict__)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(_ConvNd, self).__setstate__(state)\n",
        "        if not hasattr(self, 'padding_mode'):\n",
        "            self.padding_mode = 'zeros'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0WYIq5PSpYY",
        "colab_type": "text"
      },
      "source": [
        "#### Writing out new convolutional filter. Same number of parameters but convolutions at multiple scales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNcy4bSNRm0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "import random\n",
        "class Conv2dMultiScale(_ConvNd):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1,\n",
        "                 bias=True, padding_mode='zeros', num_scales=2, pooling_mode='max', level = 1):\n",
        "        cur_size = kernel_size\n",
        "        kernel_size = _pair(kernel_size)\n",
        "        stride = _pair(stride)\n",
        "        padding = _pair(padding)\n",
        "        dilation = _pair(dilation)\n",
        "        super(Conv2dMultiScale, self).__init__(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
        "            False, _pair(0), groups, bias, padding_mode)\n",
        "        # self.scale = nn.UpsamplingBilinear2d(size=(8,8))\n",
        "        self.scale = []\n",
        "        for i in range(num_scales - 1):\n",
        "          self.scale.append(nn.UpsamplingBilinear2d(size=(cur_size + 2, cur_size + 2)))\n",
        "        # self.scale = nn.functional.interpolate(size=(5,5), mode='bicubic')\n",
        "        self.pooling_mode = pooling_mode\n",
        "\n",
        "    def _conv_forward(self, input, weight_para):\n",
        "        out1 = F.conv2d(input, weight_para, self.bias, self.stride,\n",
        "                        self.padding, self.dilation, self.groups)\n",
        "        for scale in self.scale:          \n",
        "          weight = scale(weight_para)\n",
        "          padding = tuple(x+1 for x in self.padding)\n",
        "          out2 = F.conv2d(input, weight, self.bias, self.stride,\n",
        "                        padding, self.dilation, self.groups)\n",
        "          out2 = F.interpolate(out2, size=out1.shape[2:], mode='bilinear', align_corners=False)         \n",
        "          if (self.pooling_mode == 'avg'):\n",
        "            out1 = (out1 + out2)\n",
        "          elif (self.pooling_mode == 'max'):\n",
        "            out1 = torch.max(out1, out2)\n",
        "          else:\n",
        "            out1 = torch.cat([out1, out2], dim=1)\n",
        "        if (self.pooling_mode == 'cat'):\n",
        "          max_pool_results = F.max_pool2d(input, 2)\n",
        "          max_pool_results = F.interpolate(max_pool_results, size=out1.shape[2:], mode='bilinear', align_corners=False)         \n",
        "          out1 = torch.cat([out1, max_pool_results], dim=1)\n",
        "          # print(out1.shape, \"--------------------------------------------------------------------\")\n",
        "        return out1\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self._conv_forward(input, self.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD7NbCG3hpTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f6de06b8-288a-4dd4-b4f2-8bb49aca8182"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnpYqRAnM8Aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "d41bbb25-a1c3-4c20-95df-f0319f6cd5b1"
      },
      "source": [
        "# Understanding sizes of CNNs, ensuring it works\n",
        "kernelSize = 5\n",
        "m = Conv2dMultiScale(3, 64, kernelSize, stride=1, padding=0, num_scales=2, pooling_mode='cat')\n",
        "input = torch.randn(20, 3, 28, 28)\n",
        "print(input.shape)\n",
        "output = m(input)\n",
        "print(output.shape)\n",
        "output = F.max_pool2d(output, 2)\n",
        "print(output.shape)\n",
        "m2 = Conv2dMultiScale(64, 64, kernelSize, stride=1, padding=0, num_scales=3)\n",
        "output = m2(output)\n",
        "print(output.shape)\n",
        "output = F.max_pool2d(output, 2)\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 3, 28, 28])\n",
            "torch.Size([20, 131, 24, 24])\n",
            "torch.Size([20, 131, 12, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-fee3bbe39c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2dMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_scales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-e29edfdf9ef8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-e29edfdf9ef8>\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight_para)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_para\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         out1 = F.conv2d(input, weight_para, self.bias, self.stride,\n\u001b[0;32m---> 24\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_para\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 64, 5, 5], expected input[20, 131, 12, 12] to have 64 channels, but got 131 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO3Ks9GN1Tef",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-emawq_CRVXu",
        "colab_type": "text"
      },
      "source": [
        "###MNIST Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufIJal8URUUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4c4b223-0d6c-4a0c-dbeb-2ca83945295c"
      },
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# test_transform = transforms.Compose([\n",
        "#     transforms.RandomAffine(degrees=0, scale=(1,1)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "train_data = dsets.CIFAR10(root = './data', train = True,\n",
        "                        transform = train_transform, download = True)\n",
        "\n",
        "# test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "#                        transform = test_transform)\n",
        "\n",
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "\n",
        "# test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "#                                       batch_size = batch_size, \n",
        "#                                       shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sls9YItQaOm",
        "colab_type": "text"
      },
      "source": [
        "###Train and Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJAYjO4XQf5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, lr=0.001, num_epochs=10, batch_size=64):  \n",
        "  if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam( net.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for i ,(images,labels) in enumerate(train_gen):\n",
        "      if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(images)\n",
        "      loss = loss_function(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if (i+1) % 100 == 0:\n",
        "        print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                  %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))\n",
        "def test(net):  \n",
        "  if(net.multiScale):\n",
        "    print('RESULTS OF MULTISCALE CNN')\n",
        "  else:\n",
        "    print('RESULTS OF STANDARD CNN')\n",
        "  if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # loss_function = nn.CrossEntropyLoss()\n",
        "  for images,labels in train_gen:\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    output = net(images)\n",
        "    # loss = loss_function(outputs, labels)\n",
        "    _, predicted = torch.max(output,1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "  train_acc = (100*correct.cpu().numpy())/(total+1)\n",
        "  print('Train accuracy of the model: %.3f %%' %(train_acc))\n",
        "  print(correct, total)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images,labels in test_gen:\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    output = net(images)\n",
        "    # loss = loss_function(outputs, labels)\n",
        "    _, predicted = torch.max(output,1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "  test_acc = (100*correct.cpu().numpy())/(total+1)\n",
        "  print('Test accuracy of the model: %.3f %%' %(test_acc))\n",
        "  print(correct, total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhSgsk9CRcW6",
        "colab_type": "text"
      },
      "source": [
        "###Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25WykbLSM74b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, multiScale=True, cat = False, level_1=2, level_2=2):\n",
        "        super(Net, self).__init__()\n",
        "        self.multiScale = multiScale\n",
        "        self.cat = cat\n",
        "        self.level_1 = level_1\n",
        "        self.level_2 = level_2\n",
        "        if(self.multiScale and not cat):\n",
        "          self.conv1 = Conv2dMultiScale(3, 64, 5, 1, pooling_mode='max', num_scales=level_1)\n",
        "          self.conv2 = Conv2dMultiScale(64, 64, 5, 1, pooling_mode='max', num_scales=level_2)\n",
        "          self.fc = nn.Linear(64 * 5 * 5, 384)\n",
        "        elif(cat and self.multiScale):\n",
        "          self.conv1 = Conv2dMultiScale(3, 64, 5, 1, pooling_mode='cat', num_scales=level_1)\n",
        "          self.conv2 = Conv2dMultiScale(64 * level_1 + 3, 64 * level_1 + 3, 5, 1, pooling_mode='cat', num_scales=level_2)\n",
        "          self.fc = nn.Linear((64 * level_1 + 3) * 5 * 5 * (level_2 + 1), 384)\n",
        "        else:\n",
        "          self.conv1 = nn.Conv2d(3, 64, 5, 1)\n",
        "          self.conv2 = nn.Conv2d(64, 64, 5, 1)\n",
        "          self.fc = nn.Linear(64 * 5 * 5, 384)\n",
        "        self.fc1 = nn.Linear(384, 192)\n",
        "        self.fc2 = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)        \n",
        "        x = F.relu(x)    \n",
        "        x = F.max_pool2d(x, 2)  \n",
        "        x = self.conv2(x)       \n",
        "        x = F.relu(x)      \n",
        "        x = F.max_pool2d(x, 2)     \n",
        "        x = torch.flatten(x, 1)       \n",
        "        x = self.fc(x)\n",
        "        x = F.relu(x)      \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        # else: \n",
        "        return output\n",
        "\n",
        "\n",
        "net = Net(multiScale=True, cat= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKIwl6b3RffA",
        "colab_type": "text"
      },
      "source": [
        "###Train, Test and Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp690s02VZM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65c0092b-564d-47ec-d73e-428d1cbb148c"
      },
      "source": [
        "train(net, lr=0.0003, num_epochs=3)\n",
        "train(net, lr=0.001, num_epochs=10)\n",
        "train(net, lr=0.0003, num_epochs=6)\n",
        "# train(net, lr=0.001, num_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Step [100/781], Loss: 1.7583\n",
            "Epoch [1/3], Step [200/781], Loss: 1.3727\n",
            "Epoch [1/3], Step [300/781], Loss: 1.4270\n",
            "Epoch [1/3], Step [400/781], Loss: 1.3773\n",
            "Epoch [1/3], Step [500/781], Loss: 1.5414\n",
            "Epoch [1/3], Step [600/781], Loss: 1.2664\n",
            "Epoch [1/3], Step [700/781], Loss: 1.1739\n",
            "Epoch [2/3], Step [100/781], Loss: 1.1914\n",
            "Epoch [2/3], Step [200/781], Loss: 1.0736\n",
            "Epoch [2/3], Step [300/781], Loss: 1.2605\n",
            "Epoch [2/3], Step [400/781], Loss: 0.9861\n",
            "Epoch [2/3], Step [500/781], Loss: 1.0460\n",
            "Epoch [2/3], Step [600/781], Loss: 1.3016\n",
            "Epoch [2/3], Step [700/781], Loss: 1.2377\n",
            "Epoch [3/3], Step [100/781], Loss: 1.3208\n",
            "Epoch [3/3], Step [200/781], Loss: 0.9185\n",
            "Epoch [3/3], Step [300/781], Loss: 1.0715\n",
            "Epoch [3/3], Step [400/781], Loss: 1.0350\n",
            "Epoch [3/3], Step [500/781], Loss: 0.8666\n",
            "Epoch [3/3], Step [600/781], Loss: 1.0616\n",
            "Epoch [3/3], Step [700/781], Loss: 0.9844\n",
            "Epoch [1/10], Step [100/781], Loss: 1.2848\n",
            "Epoch [1/10], Step [200/781], Loss: 1.0146\n",
            "Epoch [1/10], Step [300/781], Loss: 0.9350\n",
            "Epoch [1/10], Step [400/781], Loss: 1.1720\n",
            "Epoch [1/10], Step [500/781], Loss: 1.0911\n",
            "Epoch [1/10], Step [600/781], Loss: 1.1036\n",
            "Epoch [1/10], Step [700/781], Loss: 0.9275\n",
            "Epoch [2/10], Step [100/781], Loss: 0.8589\n",
            "Epoch [2/10], Step [200/781], Loss: 0.8903\n",
            "Epoch [2/10], Step [300/781], Loss: 0.5474\n",
            "Epoch [2/10], Step [400/781], Loss: 0.9843\n",
            "Epoch [2/10], Step [500/781], Loss: 0.6857\n",
            "Epoch [2/10], Step [600/781], Loss: 0.8170\n",
            "Epoch [2/10], Step [700/781], Loss: 0.8677\n",
            "Epoch [3/10], Step [100/781], Loss: 0.8329\n",
            "Epoch [3/10], Step [200/781], Loss: 0.7401\n",
            "Epoch [3/10], Step [300/781], Loss: 0.8741\n",
            "Epoch [3/10], Step [400/781], Loss: 0.7682\n",
            "Epoch [3/10], Step [500/781], Loss: 0.5250\n",
            "Epoch [3/10], Step [600/781], Loss: 0.8475\n",
            "Epoch [3/10], Step [700/781], Loss: 0.7911\n",
            "Epoch [4/10], Step [100/781], Loss: 0.5560\n",
            "Epoch [4/10], Step [200/781], Loss: 0.5853\n",
            "Epoch [4/10], Step [300/781], Loss: 0.8303\n",
            "Epoch [4/10], Step [400/781], Loss: 0.8641\n",
            "Epoch [4/10], Step [500/781], Loss: 0.6222\n",
            "Epoch [4/10], Step [600/781], Loss: 0.7609\n",
            "Epoch [4/10], Step [700/781], Loss: 0.8055\n",
            "Epoch [5/10], Step [100/781], Loss: 0.5292\n",
            "Epoch [5/10], Step [200/781], Loss: 0.5703\n",
            "Epoch [5/10], Step [300/781], Loss: 0.5515\n",
            "Epoch [5/10], Step [400/781], Loss: 0.5197\n",
            "Epoch [5/10], Step [500/781], Loss: 0.4490\n",
            "Epoch [5/10], Step [600/781], Loss: 0.5135\n",
            "Epoch [5/10], Step [700/781], Loss: 0.5123\n",
            "Epoch [6/10], Step [100/781], Loss: 0.4467\n",
            "Epoch [6/10], Step [200/781], Loss: 0.5651\n",
            "Epoch [6/10], Step [300/781], Loss: 0.4891\n",
            "Epoch [6/10], Step [400/781], Loss: 0.5980\n",
            "Epoch [6/10], Step [500/781], Loss: 0.3709\n",
            "Epoch [6/10], Step [600/781], Loss: 0.5474\n",
            "Epoch [6/10], Step [700/781], Loss: 0.3899\n",
            "Epoch [7/10], Step [100/781], Loss: 0.3091\n",
            "Epoch [7/10], Step [200/781], Loss: 0.3461\n",
            "Epoch [7/10], Step [300/781], Loss: 0.3404\n",
            "Epoch [7/10], Step [400/781], Loss: 0.4718\n",
            "Epoch [7/10], Step [500/781], Loss: 0.2076\n",
            "Epoch [7/10], Step [600/781], Loss: 0.3997\n",
            "Epoch [7/10], Step [700/781], Loss: 0.4072\n",
            "Epoch [8/10], Step [100/781], Loss: 0.3608\n",
            "Epoch [8/10], Step [200/781], Loss: 0.2028\n",
            "Epoch [8/10], Step [300/781], Loss: 0.4228\n",
            "Epoch [8/10], Step [400/781], Loss: 0.4426\n",
            "Epoch [8/10], Step [500/781], Loss: 0.3336\n",
            "Epoch [8/10], Step [600/781], Loss: 0.2197\n",
            "Epoch [8/10], Step [700/781], Loss: 0.3355\n",
            "Epoch [9/10], Step [100/781], Loss: 0.2414\n",
            "Epoch [9/10], Step [200/781], Loss: 0.4283\n",
            "Epoch [9/10], Step [300/781], Loss: 0.4203\n",
            "Epoch [9/10], Step [400/781], Loss: 0.3523\n",
            "Epoch [9/10], Step [500/781], Loss: 0.2387\n",
            "Epoch [9/10], Step [600/781], Loss: 0.5239\n",
            "Epoch [9/10], Step [700/781], Loss: 0.2682\n",
            "Epoch [10/10], Step [100/781], Loss: 0.1590\n",
            "Epoch [10/10], Step [200/781], Loss: 0.1894\n",
            "Epoch [10/10], Step [300/781], Loss: 0.2715\n",
            "Epoch [10/10], Step [400/781], Loss: 0.2820\n",
            "Epoch [10/10], Step [500/781], Loss: 0.1856\n",
            "Epoch [10/10], Step [600/781], Loss: 0.3418\n",
            "Epoch [10/10], Step [700/781], Loss: 0.4363\n",
            "Epoch [1/6], Step [100/781], Loss: 0.0857\n",
            "Epoch [1/6], Step [200/781], Loss: 0.0957\n",
            "Epoch [1/6], Step [300/781], Loss: 0.0432\n",
            "Epoch [1/6], Step [400/781], Loss: 0.0331\n",
            "Epoch [1/6], Step [500/781], Loss: 0.0614\n",
            "Epoch [1/6], Step [600/781], Loss: 0.0575\n",
            "Epoch [1/6], Step [700/781], Loss: 0.0398\n",
            "Epoch [2/6], Step [100/781], Loss: 0.0469\n",
            "Epoch [2/6], Step [200/781], Loss: 0.0212\n",
            "Epoch [2/6], Step [300/781], Loss: 0.0106\n",
            "Epoch [2/6], Step [400/781], Loss: 0.0403\n",
            "Epoch [2/6], Step [500/781], Loss: 0.0119\n",
            "Epoch [2/6], Step [600/781], Loss: 0.0731\n",
            "Epoch [2/6], Step [700/781], Loss: 0.0169\n",
            "Epoch [3/6], Step [100/781], Loss: 0.0189\n",
            "Epoch [3/6], Step [200/781], Loss: 0.0368\n",
            "Epoch [3/6], Step [300/781], Loss: 0.0523\n",
            "Epoch [3/6], Step [400/781], Loss: 0.0277\n",
            "Epoch [3/6], Step [500/781], Loss: 0.0059\n",
            "Epoch [3/6], Step [600/781], Loss: 0.0409\n",
            "Epoch [3/6], Step [700/781], Loss: 0.0784\n",
            "Epoch [4/6], Step [100/781], Loss: 0.0171\n",
            "Epoch [4/6], Step [200/781], Loss: 0.0133\n",
            "Epoch [4/6], Step [300/781], Loss: 0.0148\n",
            "Epoch [4/6], Step [400/781], Loss: 0.0622\n",
            "Epoch [4/6], Step [500/781], Loss: 0.0049\n",
            "Epoch [4/6], Step [600/781], Loss: 0.0928\n",
            "Epoch [4/6], Step [700/781], Loss: 0.0383\n",
            "Epoch [5/6], Step [100/781], Loss: 0.0134\n",
            "Epoch [5/6], Step [200/781], Loss: 0.0350\n",
            "Epoch [5/6], Step [300/781], Loss: 0.0039\n",
            "Epoch [5/6], Step [400/781], Loss: 0.0177\n",
            "Epoch [5/6], Step [500/781], Loss: 0.0178\n",
            "Epoch [5/6], Step [600/781], Loss: 0.0691\n",
            "Epoch [5/6], Step [700/781], Loss: 0.0624\n",
            "Epoch [6/6], Step [100/781], Loss: 0.0057\n",
            "Epoch [6/6], Step [200/781], Loss: 0.0476\n",
            "Epoch [6/6], Step [300/781], Loss: 0.0189\n",
            "Epoch [6/6], Step [400/781], Loss: 0.0160\n",
            "Epoch [6/6], Step [500/781], Loss: 0.0185\n",
            "Epoch [6/6], Step [600/781], Loss: 0.0213\n",
            "Epoch [6/6], Step [700/781], Loss: 0.0124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkmy6hdofGLt",
        "colab_type": "text"
      },
      "source": [
        "###Test on CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtRE-fD3nNS7",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PsvCNFe9Xt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4b0aa6df-3b5b-4e22-de01-3c34d0d75f37"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\",\"num_scale:\",net.level_1,\",\",net.level_2,\"\\nnet.Multiscale=\",net.multiScale,\"\\ncat=\",net.cat)\n",
        "test(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Architecture:\n",
            " num_scale: 2 , 2 \n",
            "net.Multiscale= True \n",
            "cat= True\n",
            "RESULTS OF MULTISCALE CNN\n",
            "Train accuracy of the model: 99.498 %\n",
            "tensor(49750, device='cuda:0') 50000\n",
            "Test accuracy of the model: 73.463 %\n",
            "tensor(7347, device='cuda:0') 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNWAFnSonUOy",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y4ZFNmftV5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e0664aa4-38b7-4e3d-b5b3-84f87a9ef139"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(28),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\",\"num_scale:\",net.level_1,\",\",net.level_2,\"\\nnet.Multiscale=\",net.multiScale,\"\\ncat=\",net.cat)\n",
        "test(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Architecture:\n",
            " num_scale: 2 , 2 \n",
            "net.Multiscale= True \n",
            "cat= True\n",
            "RESULTS OF MULTISCALE CNN\n",
            "Train accuracy of the model: 99.498 %\n",
            "tensor(49750, device='cuda:0') 50000\n",
            "Test accuracy of the model: 64.504 %\n",
            "tensor(6451, device='cuda:0') 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRyjrSxKnWYI",
        "colab_type": "text"
      },
      "source": [
        "###32 -> 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iafy3nlNnIkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "df5d42fd-8410-431e-ec34-bef253cf30b8"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.CenterCrop(24),\n",
        "    transforms.Resize(32, interpolation=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = test_transform, download=True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size, \n",
        "                                      shuffle = False)\n",
        "print(\"Architecture:\\n\",\"num_scale:\",net.level_1,\",\",net.level_2,\"\\nnet.Multiscale=\",net.multiScale,\"\\ncat=\",net.cat)\n",
        "test(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Architecture:\n",
            " num_scale: 2 , 2 \n",
            "net.Multiscale= True \n",
            "cat= True\n",
            "RESULTS OF MULTISCALE CNN\n",
            "Train accuracy of the model: 99.498 %\n",
            "tensor(49750, device='cuda:0') 50000\n",
            "Test accuracy of the model: 51.555 %\n",
            "tensor(5156, device='cuda:0') 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}